A Dead Letter Topic (DLT) in Kafka is used to handle messages that cannot be processed successfully by consumers.
Instead of losing such problematic messages, they are redirected to a special Kafka topic (the DLT) for later analysis, debugging,
or reprocessing.

When to Use a Dead Letter Topic

Deserialization failures

Business logic errors

Data format issues

Schema mismatches



---

How It Works (Spring Kafka Example)

1. Consumer Configuration with Error Handling

@Bean
public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory(
        ConsumerFactory<String, String> consumerFactory,
        KafkaTemplate<String, String> kafkaTemplate) {

    ConcurrentKafkaListenerContainerFactory<String, String> factory =
            new ConcurrentKafkaListenerContainerFactory<>();

    factory.setConsumerFactory(consumerFactory);

    // Error handler to send to DLT
    factory.setErrorHandler(new DeadLetterPublishingRecoverer(kafkaTemplate),
            new FixedBackOff(1000L, 2)); // Retry twice before sending to DLT

    return factory;
}

2. Kafka Listener

@KafkaListener(topics = "main-topic", groupId = "my-group")
public void listen(String message) {
    // Business logic that might throw an exception
}

3. Dead Letter Topic Naming Convention

By default, Spring Kafka names the DLT as:

<original-topic-name>.DLT

E.g., for main-topic, it will be main-topic.DLT.


---

Benefits of Using DLT

Keeps the main topic clean and fast

Allows better monitoring and alerting

Enables retries after fixes

Prevents data loss

*********************************************
Hereâ€™s a complete end-to-end working example of a Kafka setup in Spring Boot using a Dead Letter Topic (DLT):


---

1. Maven Dependencies

<dependencies>
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka</artifactId>
    </dependency>
</dependencies>


---

2. Kafka Configuration

@Configuration
public class KafkaConfig {

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory(
            ConsumerFactory<String, String> consumerFactory,
            KafkaTemplate<String, String> kafkaTemplate) {

        ConcurrentKafkaListenerContainerFactory<String, String> factory =
                new ConcurrentKafkaListenerContainerFactory<>();

        factory.setConsumerFactory(consumerFactory);

        factory.setCommonErrorHandler(new DefaultErrorHandler(
                new DeadLetterPublishingRecoverer(kafkaTemplate),
                new FixedBackOff(1000L, 2))); // Retry twice, then send to DLT

        return factory;
    }
}


---

3. Kafka Listener (Consumer)

@Component
public class MessageListener {

    @KafkaListener(topics = "my-topic", groupId = "my-group")
    public void listen(String message) {
        System.out.println("Received: " + message);

        // Simulate failure for specific message
        if (message.contains("fail")) {
            throw new RuntimeException("Processing failed for message: " + message);
        }
    }
}


---

4. Kafka Producer

@RestController
@RequestMapping("/kafka")
public class MessageProducer {

    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;

    @PostMapping("/send")
    public String sendMessage(@RequestParam String msg) {
        kafkaTemplate.send("my-topic", msg);
        return "Sent: " + msg;
    }
}


---

5. Dead Letter Topic Listener (Optional for Debugging)

@Component
public class DeadLetterListener {

    @KafkaListener(topics = "my-topic.DLT", groupId = "dlt-group")
    public void handleDLT(String message) {
        System.out.println("DLT received: " + message);
    }
}


---

6. Create Topics (CLI or Admin Tool)

kafka-topics.sh --create --topic my-topic --bootstrap-server localhost:9092
kafka-topics.sh --create --topic my-topic.DLT --bootstrap-server localhost:9092


---

Usage

Send a message using:

curl -X POST "http://localhost:8080/kafka/send?msg=hello"
curl -X POST "http://localhost:8080/kafka/send?msg=fail_this"

The first message is processed normally.

The second will fail, retry 2 times, then land in my-topic.DLT.


********************************

Great question!

The Dead Letter Topic (DLT) Listener is a consumer-side configuration, not producer-side.


---

Why?

The DLT is used when a consumer fails to process a message. After retrying (if configured), Kafka or the framework (like Spring Kafka) 
sends the failed message to a DLT. To monitor or debug these failures, you need another consumer to read from the DLT.


---

Where to configure what:

Component	Configuration Side	Purpose

Dead Letter Topic Listener	Consumer side	To consume and debug failed messages
DLT error handler (recoverer)	Consumer side	Tells Kafka what to do on failure (send to DLT)
Producer config	Producer side	Optional; doesn't need to know about DLT



---

Example Summary

Your main consumer listens to my-topic.

You configure error handling (e.g. DeadLetterPublishingRecoverer) in the consumer factory.

If a message fails, it's sent to my-topic.DLT.

You set up a separate listener (consumer) for my-topic.DLT to log/debug/retry.



---







